{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538abfa3",
   "metadata": {},
   "source": [
    "### The idea here is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7aab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PossessionDataset(Dataset):\n",
    "    def __init__(self, sequences, cond_vecs, T):\n",
    "        \"\"\"\n",
    "        sequences: list of dicts, each dict has keys:\n",
    "            'type', 'sz', 'ez', 'out', 'dt', 'term'  -> each is a list of int IDs (len <= T)\n",
    "        cond_vecs: torch.FloatTensor [N, C]\n",
    "        \"\"\"\n",
    "        self.seqs = sequences\n",
    "        self.cond = cond_vecs\n",
    "        self.T = T\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        s = self.seqs[i]\n",
    "        # pad to T\n",
    "        def pad(x, pad_id=0):\n",
    "            x = x[:self.T]\n",
    "            if len(x) < self.T:\n",
    "                x = x + [pad_id] * (self.T - len(x))\n",
    "            return torch.tensor(x, dtype=torch.long)\n",
    "\n",
    "        type_ids = pad(s[\"type\"], 0)\n",
    "        sz_ids   = pad(s[\"sz\"],   0)\n",
    "        ez_ids   = pad(s[\"ez\"],   0)\n",
    "        out_ids  = pad(s[\"out\"],  0)\n",
    "        dt_ids   = pad(s[\"dt\"],   0)\n",
    "        term_ids = pad(s[\"term\"], 0)\n",
    "\n",
    "        # mask: real tokens are non-pad in type stream\n",
    "        mask = (type_ids != 0).float()\n",
    "\n",
    "        # teacher forcing: decoder predicts next step\n",
    "        x = torch.stack([type_ids, sz_ids, ez_ids, out_ids, dt_ids, term_ids], dim=-1)  # [T, 6]\n",
    "        return x, self.cond[i], mask\n",
    "\n",
    "\n",
    "def masked_ce(logits, target, mask):\n",
    "    # logits: [B,T,V], target: [B,T], mask: [B,T]\n",
    "    B,T,V = logits.shape\n",
    "    loss = F.cross_entropy(logits.reshape(B*T, V), target.reshape(B*T), reduction=\"none\")\n",
    "    loss = loss.reshape(B,T) * mask\n",
    "    return loss.sum() / (mask.sum() + 1e-8)\n",
    "\n",
    "def kld(mu, logv):\n",
    "    return -0.5 * torch.mean(1 + logv - mu.pow(2) - logv.exp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df472e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SeqCVAE(nn.Module):\n",
    "    def __init__(self, n_types, n_zones, n_out, n_dt, n_term,\n",
    "                 emb=32, hidden=256, zdim=32, cdim=12):\n",
    "        super().__init__()\n",
    "\n",
    "        # embeddings for each categorical stream\n",
    "        self.type_emb = nn.Embedding(n_types, emb, padding_idx=0)\n",
    "        self.sz_emb   = nn.Embedding(n_zones, emb, padding_idx=0)\n",
    "        self.ez_emb   = nn.Embedding(n_zones, emb, padding_idx=0)\n",
    "        self.out_emb  = nn.Embedding(n_out,   emb, padding_idx=0)\n",
    "        self.dt_emb   = nn.Embedding(n_dt,    emb, padding_idx=0)\n",
    "        self.term_emb = nn.Embedding(n_term,  emb, padding_idx=0)\n",
    "\n",
    "        in_dim = emb * 6\n",
    "\n",
    "        # encoder\n",
    "        self.enc_rnn = nn.GRU(in_dim + cdim, hidden, batch_first=True)\n",
    "        self.to_mu   = nn.Linear(hidden, zdim)\n",
    "        self.to_logv = nn.Linear(hidden, zdim)\n",
    "\n",
    "        # decoder\n",
    "        self.dec_rnn = nn.GRU(in_dim + cdim + zdim, hidden, batch_first=True)\n",
    "\n",
    "        # heads: predict each categorical field\n",
    "        self.h_type = nn.Linear(hidden, n_types)\n",
    "        self.h_sz   = nn.Linear(hidden, n_zones)\n",
    "        self.h_ez   = nn.Linear(hidden, n_zones)\n",
    "        self.h_out  = nn.Linear(hidden, n_out)\n",
    "        self.h_dt   = nn.Linear(hidden, n_dt)\n",
    "        self.h_term = nn.Linear(hidden, n_term)\n",
    "\n",
    "    def embed_step(self, x):\n",
    "        # x: [B, T, 6] -> embeddings concat [B, T, 6*emb]\n",
    "        t, sz, ez, out, dt, term = x.unbind(dim=-1)\n",
    "        e = torch.cat([\n",
    "            self.type_emb(t),\n",
    "            self.sz_emb(sz),\n",
    "            self.ez_emb(ez),\n",
    "            self.out_emb(out),\n",
    "            self.dt_emb(dt),\n",
    "            self.term_emb(term),\n",
    "        ], dim=-1)\n",
    "        return e\n",
    "\n",
    "    def encode(self, x, c):\n",
    "        B, T, _ = x.shape\n",
    "        e = self.embed_step(x)\n",
    "        c_rep = c.unsqueeze(1).expand(B, T, c.shape[-1])\n",
    "        inp = torch.cat([e, c_rep], dim=-1)\n",
    "        _, h = self.enc_rnn(inp)     # h: [1, B, hidden]\n",
    "        h = h.squeeze(0)\n",
    "        mu = self.to_mu(h)\n",
    "        logv = self.to_logv(h)\n",
    "        return mu, logv\n",
    "\n",
    "    def reparam(self, mu, logv):\n",
    "        std = torch.exp(0.5 * logv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, x_in, z, c):\n",
    "        # teacher forcing: x_in is shifted right sequence (B,T,6)\n",
    "        B, T, _ = x_in.shape\n",
    "        e = self.embed_step(x_in)\n",
    "        c_rep = c.unsqueeze(1).expand(B, T, c.shape[-1])\n",
    "        z_rep = z.unsqueeze(1).expand(B, T, z.shape[-1])\n",
    "        inp = torch.cat([e, c_rep, z_rep], dim=-1)\n",
    "        out, _ = self.dec_rnn(inp)  # [B,T,hidden]\n",
    "        return {\n",
    "            \"type\": self.h_type(out),\n",
    "            \"sz\":   self.h_sz(out),\n",
    "            \"ez\":   self.h_ez(out),\n",
    "            \"out\":  self.h_out(out),\n",
    "            \"dt\":   self.h_dt(out),\n",
    "            \"term\": self.h_term(out),\n",
    "        }\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        mu, logv = self.encode(x, c)\n",
    "        z = self.reparam(mu, logv)\n",
    "\n",
    "        # shift right for decoder input\n",
    "        x_in = x.clone()\n",
    "        x_in[:, 1:] = x[:, :-1]      # teacher forcing\n",
    "        x_in[:, 0] = 0               # first token PAD (or a START token if you add one)\n",
    "\n",
    "        logits = self.decode(x_in, z, c)\n",
    "        return logits, mu, logv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13dc766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even larger loader\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _safe_id(x):\n",
    "    if isinstance(x, dict) and \"id\" in x:\n",
    "        return x[\"id\"]\n",
    "    return np.nan\n",
    "\n",
    "def _safe_name(x):\n",
    "    if isinstance(x, dict) and \"name\" in x:\n",
    "        return x[\"name\"]\n",
    "    return None\n",
    "\n",
    "def _safe_bool(e: dict, key: str, default=False) -> bool:\n",
    "    v = e.get(key, default)\n",
    "    return bool(v) if v is not None else bool(default)\n",
    "\n",
    "def _parse_timestamp_to_sec(ts: str):\n",
    "    \"\"\"\n",
    "    StatsBomb timestamp usually looks like '00:12:34.123' (HH:MM:SS.sss).\n",
    "    Returns seconds within the current period; if parsing fails returns np.nan.\n",
    "    \"\"\"\n",
    "    if not isinstance(ts, str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        # split hh:mm:ss(.ms)\n",
    "        hh, mm, ss = ts.split(\":\")\n",
    "        return float(hh) * 3600.0 + float(mm) * 60.0 + float(ss)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def _period_offset_seconds(period):\n",
    "    \"\"\"\n",
    "    Simple offsets for regulation time.\n",
    "    Period 1: 0\n",
    "    Period 2: 45*60\n",
    "    Period 3: 90*60 (ET1)\n",
    "    Period 4: 105*60 (ET2)\n",
    "    Unknown -> 0\n",
    "    \"\"\"\n",
    "    try:\n",
    "        p = int(period)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "    if p == 1:\n",
    "        return 0.0\n",
    "    if p == 2:\n",
    "        return 45.0 * 60.0\n",
    "    if p == 3:\n",
    "        return 90.0 * 60.0\n",
    "    if p == 4:\n",
    "        return 105.0 * 60.0\n",
    "    return 0.0\n",
    "\n",
    "def _generic_outcome_for_event(e: dict):\n",
    "    \"\"\"\n",
    "    Returns (outcome_name, success_bool_or_nan) using StatsBomb conventions.\n",
    "    - Many nested outcome fields exist; missing often implies 'Complete/Success'.\n",
    "    - For event types without a notion of outcome, returns (None, np.nan).\n",
    "    \"\"\"\n",
    "    t = _safe_name(e.get(\"type\"))\n",
    "\n",
    "    # PASS\n",
    "    if t == \"Pass\" and isinstance(e.get(\"pass\"), dict):\n",
    "        out = e[\"pass\"].get(\"outcome\")\n",
    "        if isinstance(out, dict):\n",
    "            return out.get(\"name\"), False\n",
    "        # missing outcome => completed\n",
    "        return \"Complete\", True\n",
    "\n",
    "    # SHOT\n",
    "    if t == \"Shot\" and isinstance(e.get(\"shot\"), dict):\n",
    "        out = e[\"shot\"].get(\"outcome\")\n",
    "        if isinstance(out, dict):\n",
    "            # success is ambiguous (goal vs on target etc). keep np.nan for boolean.\n",
    "            return out.get(\"name\"), np.nan\n",
    "        return None, np.nan\n",
    "\n",
    "    # DRIBBLE\n",
    "    if t == \"Dribble\" and isinstance(e.get(\"dribble\"), dict):\n",
    "        out = e[\"dribble\"].get(\"outcome\")\n",
    "        if isinstance(out, dict):\n",
    "            name = out.get(\"name\")\n",
    "            # StatsBomb uses \"Complete\"/\"Incomplete\"\n",
    "            if name is not None:\n",
    "                return name, (name.lower() == \"complete\")\n",
    "        return None, np.nan\n",
    "\n",
    "    # DUEL\n",
    "    if t == \"Duel\" and isinstance(e.get(\"duel\"), dict):\n",
    "        out = e[\"duel\"].get(\"outcome\")\n",
    "        if isinstance(out, dict):\n",
    "            name = out.get(\"name\")\n",
    "            # Often \"Won\"/\"Lost\"/\"Success In Play\"/etc\n",
    "            if name is not None:\n",
    "                low = name.lower()\n",
    "                if low in (\"won\", \"success\", \"success in play\", \"success out\"):\n",
    "                    return name, True\n",
    "                if low in (\"lost\", \"failure\"):\n",
    "                    return name, False\n",
    "            return name, np.nan\n",
    "        return None, np.nan\n",
    "\n",
    "    # INTERCEPTION\n",
    "    if t == \"Interception\" and isinstance(e.get(\"interception\"), dict):\n",
    "        out = e[\"interception\"].get(\"outcome\")\n",
    "        if isinstance(out, dict):\n",
    "            name = out.get(\"name\")\n",
    "            if name is not None:\n",
    "                low = name.lower()\n",
    "                if low in (\"won\", \"success\"):\n",
    "                    return name, True\n",
    "                if low in (\"lost\", \"failure\"):\n",
    "                    return name, False\n",
    "            return name, np.nan\n",
    "        # If no outcome, treat as success-ish\n",
    "        return \"Won\", True\n",
    "\n",
    "    # BALL RECOVERY\n",
    "    if t == \"Ball Recovery\" and isinstance(e.get(\"ball_recovery\"), dict):\n",
    "        fail = e[\"ball_recovery\"].get(\"recovery_failure\")\n",
    "        if fail is True:\n",
    "            return \"Failure\", False\n",
    "        if fail is False:\n",
    "            return \"Success\", True\n",
    "        return None, np.nan\n",
    "\n",
    "    # MISCONTROL (always “bad touch” in spirit)\n",
    "    if t == \"Miscontrol\":\n",
    "        return \"Miscontrol\", False\n",
    "\n",
    "    # CLEARANCE (no explicit outcome)\n",
    "    if t == \"Clearance\":\n",
    "        return None, np.nan\n",
    "\n",
    "    # PRESSURE (no explicit success)\n",
    "    if t == \"Pressure\":\n",
    "        return None, np.nan\n",
    "\n",
    "    # FOUL COMMITTED / WON are separate event types (no outcome field)\n",
    "    if t in (\"Foul Committed\", \"Foul Won\"):\n",
    "        return None, np.nan\n",
    "\n",
    "    # DEFAULT\n",
    "    return None, np.nan\n",
    "\n",
    "def flatten_events_for_match(sb_data_root: Path, match_row: dict) -> pd.DataFrame:\n",
    "    match_id = match_row[\"match_id\"]\n",
    "    p = sb_data_root / \"events\" / f\"{match_id}.json\"\n",
    "    ev = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    rows = []\n",
    "    for e in ev:\n",
    "        loc = e.get(\"location\", None)\n",
    "        x = loc[0] if isinstance(loc, list) and len(loc) >= 2 else np.nan\n",
    "        y = loc[1] if isinstance(loc, list) and len(loc) >= 2 else np.nan\n",
    "\n",
    "        # end locations (pass/carry/shot)\n",
    "        endx = endy = np.nan\n",
    "        pass_length = np.nan\n",
    "        pass_subtype = None\n",
    "\n",
    "        # extra pass fields (lightweight, useful later)\n",
    "        pass_height = None\n",
    "        pass_cross = False\n",
    "        pass_body_part = None\n",
    "        pass_outcome = None\n",
    "        pass_recipient_id = np.nan\n",
    "        pass_recipient_name = None\n",
    "\n",
    "        # carry distance (computed)\n",
    "        carry_length = np.nan\n",
    "\n",
    "        # shot extras\n",
    "        shot_endx = shot_endy = np.nan\n",
    "        shot_outcome = None\n",
    "        shot_xg = np.nan\n",
    "        shot_body_part = None\n",
    "        shot_type = None\n",
    "\n",
    "        # duel subtype\n",
    "        duel_type = None\n",
    "        duel_outcome = None\n",
    "\n",
    "        # generic outcome\n",
    "        generic_outcome, success = _generic_outcome_for_event(e)\n",
    "\n",
    "        # time handling\n",
    "        ts = e.get(\"timestamp\", None)\n",
    "        t_in_period = _parse_timestamp_to_sec(ts)\n",
    "        period = e.get(\"period\", np.nan)\n",
    "        t_abs = (\n",
    "            t_in_period + _period_offset_seconds(period)\n",
    "            if not (isinstance(t_in_period, float) and np.isnan(t_in_period))\n",
    "            else np.nan\n",
    "        )\n",
    "\n",
    "        # pass/carry details\n",
    "        if isinstance(e.get(\"pass\"), dict):\n",
    "            pe = e[\"pass\"]\n",
    "            end = pe.get(\"end_location\", None)\n",
    "            if isinstance(end, list) and len(end) >= 2:\n",
    "                endx, endy = end[0], end[1]\n",
    "            pass_length = pe.get(\"length\", np.nan)\n",
    "            pass_subtype = _safe_name(pe.get(\"type\"))\n",
    "            pass_height = _safe_name(pe.get(\"height\"))\n",
    "            pass_cross = bool(pe.get(\"cross\", False))\n",
    "            pass_body_part = _safe_name(pe.get(\"body_part\"))\n",
    "\n",
    "            out = pe.get(\"outcome\")\n",
    "            pass_outcome = _safe_name(out) if isinstance(out, dict) else None\n",
    "\n",
    "            rec = pe.get(\"recipient\")\n",
    "            pass_recipient_id = _safe_id(rec)\n",
    "            pass_recipient_name = _safe_name(rec)\n",
    "\n",
    "        elif isinstance(e.get(\"carry\"), dict):\n",
    "            ce = e[\"carry\"]\n",
    "            end = ce.get(\"end_location\", None)\n",
    "            if isinstance(end, list) and len(end) >= 2:\n",
    "                endx, endy = end[0], end[1]\n",
    "            # compute carry length if we have both points\n",
    "            if not (np.isnan(x) or np.isnan(y) or np.isnan(endx) or np.isnan(endy)):\n",
    "                carry_length = float(np.hypot(endx - x, endy - y))\n",
    "\n",
    "        # shot details\n",
    "        if isinstance(e.get(\"shot\"), dict):\n",
    "            se = e[\"shot\"]\n",
    "            out = se.get(\"outcome\")\n",
    "            shot_outcome = _safe_name(out) if isinstance(out, dict) else None\n",
    "\n",
    "            end = se.get(\"end_location\", None)\n",
    "            if isinstance(end, list) and len(end) >= 2:\n",
    "                shot_endx, shot_endy = end[0], end[1]\n",
    "\n",
    "            # StatsBomb xG field in open data\n",
    "            shot_xg = se.get(\"statsbomb_xg\", np.nan)\n",
    "\n",
    "            shot_body_part = _safe_name(se.get(\"body_part\"))\n",
    "            shot_type = _safe_name(se.get(\"type\"))\n",
    "\n",
    "        # duel details\n",
    "        if isinstance(e.get(\"duel\"), dict):\n",
    "            de = e[\"duel\"]\n",
    "            duel_type = _safe_name(de.get(\"type\"))\n",
    "            duel_outcome = _safe_name(de.get(\"outcome\")) if isinstance(de.get(\"outcome\"), dict) else None\n",
    "\n",
    "        rows.append({\n",
    "            \"match_id\": match_id,\n",
    "            \"competition_id\": match_row[\"competition\"][\"competition_id\"] if isinstance(match_row.get(\"competition\"), dict) else match_row.get(\"competition_id\"),\n",
    "            \"season_id\": match_row[\"season\"][\"season_id\"] if isinstance(match_row.get(\"season\"), dict) else match_row.get(\"season_id\"),\n",
    "            \"competition_name\": match_row.get(\"competition\", {}).get(\"competition_name\", None) if isinstance(match_row.get(\"competition\"), dict) else None,\n",
    "            \"season_name\": match_row.get(\"season\", {}).get(\"season_name\", None) if isinstance(match_row.get(\"season\"), dict) else None,\n",
    "\n",
    "            # NEW: stable event keys\n",
    "            \"event_id\": e.get(\"id\", None),\n",
    "            \"event_index\": e.get(\"index\", np.nan),\n",
    "\n",
    "            \"type\": _safe_name(e.get(\"type\")),\n",
    "            \"play_pattern\": _safe_name(e.get(\"play_pattern\")),\n",
    "\n",
    "            # NEW: player\n",
    "            \"player_id\": _safe_id(e.get(\"player\")),\n",
    "            \"player_name\": _safe_name(e.get(\"player\")),\n",
    "\n",
    "            \"team_id\": _safe_id(e.get(\"team\")),\n",
    "            \"team_name\": _safe_name(e.get(\"team\")),\n",
    "            \"possession\": e.get(\"possession\", np.nan),\n",
    "            \"possession_team_id\": _safe_id(e.get(\"possession_team\")),\n",
    "            \"possession_team_name\": _safe_name(e.get(\"possession_team\")),\n",
    "\n",
    "            \"minute\": e.get(\"minute\", np.nan),\n",
    "            \"second\": e.get(\"second\", np.nan),\n",
    "            \"timestamp\": ts,\n",
    "            \"duration\": e.get(\"duration\", np.nan),\n",
    "            \"period\": period,\n",
    "\n",
    "            # NEW: convenient absolute time in seconds (for dt bins)\n",
    "            \"t_in_period_sec\": t_in_period,\n",
    "            \"t_abs_sec\": t_abs,\n",
    "\n",
    "            # locations\n",
    "            \"x\": x, \"y\": y,\n",
    "            \"endx\": endx, \"endy\": endy,\n",
    "\n",
    "            # pass\n",
    "            \"pass_length\": pass_length,\n",
    "            \"pass_subtype\": pass_subtype,\n",
    "            \"pass_height\": pass_height,\n",
    "            \"pass_cross\": pass_cross,\n",
    "            \"pass_body_part\": pass_body_part,\n",
    "            \"pass_outcome\": pass_outcome,\n",
    "            \"pass_recipient_id\": pass_recipient_id,\n",
    "            \"pass_recipient_name\": pass_recipient_name,\n",
    "\n",
    "            # carry\n",
    "            \"carry_length\": carry_length,\n",
    "\n",
    "            # shot\n",
    "            \"shot_endx\": shot_endx,\n",
    "            \"shot_endy\": shot_endy,\n",
    "            \"shot_outcome\": shot_outcome,\n",
    "            \"shot_xg\": shot_xg,\n",
    "            \"shot_body_part\": shot_body_part,\n",
    "            \"shot_type\": shot_type,\n",
    "\n",
    "            # duel\n",
    "            \"duel_type\": duel_type,\n",
    "            \"duel_outcome\": duel_outcome,\n",
    "\n",
    "            # NEW: pressure flags (event-level)\n",
    "            \"under_pressure\": _safe_bool(e, \"under_pressure\", False),\n",
    "            \"counterpress\": _safe_bool(e, \"counterpress\", False),\n",
    "\n",
    "            # NEW: generic outcome for CVAE v1\n",
    "            \"outcome\": generic_outcome,\n",
    "            \"success\": success,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "042d5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_competitions(sb_data_root: Path) -> pd.DataFrame:\n",
    "    comp_path = sb_data_root / \"competitions.json\"\n",
    "    comps = json.loads(comp_path.read_text(encoding=\"utf-8\"))\n",
    "    return pd.DataFrame(comps)\n",
    "\n",
    "TARGET = [\n",
    "    (\"England\", \"Premier League\"),\n",
    "   # (\"Spain\", \"La Liga\"),\n",
    "    #(\"Italy\", \"Serie A\"),\n",
    "    #(\"Germany\", \"1. Bundesliga\"),\n",
    "]\n",
    "\n",
    "def pick_competitions_1516(comps):\n",
    "    selected = []\n",
    "\n",
    "    for country, comp in TARGET:\n",
    "        sel = comps[\n",
    "            (comps[\"country_name\"] == country) &\n",
    "            (comps[\"competition_name\"] == comp) &\n",
    "            (comps[\"season_name\"] == \"2015/2016\")\n",
    "        ]\n",
    "\n",
    "        if sel.empty:\n",
    "            raise ValueError(f\"Missing: {country} {comp} 2015/2016\")\n",
    "\n",
    "        selected.append(sel.iloc[0])\n",
    "\n",
    "    return pd.DataFrame(selected)\n",
    "def load_matches(sb_data_root: Path, competition_id: int, season_id: int) -> pd.DataFrame:\n",
    "    p = sb_data_root / \"matches\" / str(competition_id) / f\"{season_id}.json\"\n",
    "    matches = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    return pd.DataFrame(matches)\n",
    "def load_all_events_1516(sb_data_root: Path) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    comps = load_competitions(sb_data_root)\n",
    "    picked = pick_competitions_1516(comps)\n",
    "\n",
    "    all_matches = []\n",
    "    for _, r in picked.iterrows():\n",
    "        m = load_matches(sb_data_root, int(r[\"competition_id\"]), int(r[\"season_id\"]))\n",
    "        # enrich for convenience\n",
    "        m[\"competition_name\"] = r[\"competition_name\"]\n",
    "        m[\"season_name\"] = r[\"season_name\"]\n",
    "        all_matches.append(m)\n",
    "\n",
    "    matches_df = pd.concat(all_matches, ignore_index=True)\n",
    "\n",
    "    # Load events\n",
    "    event_dfs = []\n",
    "    for _, mr in matches_df.iterrows():\n",
    "        event_dfs.append(flatten_events_for_match(sb_data_root, mr.to_dict()))\n",
    "\n",
    "    events_df = pd.concat(event_dfs, ignore_index=True)\n",
    "\n",
    "    # create a \"league\" label that matches your normalization bucket\n",
    "    events_df[\"league_season\"] = events_df[\"competition_name\"].fillna(\"\") + \" | \" + events_df[\"season_name\"].fillna(\"\")\n",
    "    matches_df[\"league_season\"] = matches_df[\"competition_name\"].fillna(\"\") + \" | \" + matches_df[\"season_name\"].fillna(\"\")\n",
    "\n",
    "    return comps, matches_df, events_df\n",
    "DATA_ROOT = Path(os.environ[\"EXJOBB_DATA\"])\n",
    "sb_root = DATA_ROOT / \"open-data-master\" / \"data\"\n",
    "comps = pd.read_json(sb_root / \"competitions.json\")\n",
    "comps, matches_df, events_df = load_all_events_1516(sb_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e51879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1313783, 49)\n",
      "['match_id', 'competition_id', 'season_id', 'competition_name', 'season_name', 'event_id', 'event_index', 'type', 'play_pattern', 'player_id', 'player_name', 'team_id', 'team_name', 'possession', 'possession_team_id', 'possession_team_name', 'minute', 'second', 'timestamp', 'duration', 'period', 't_in_period_sec', 't_abs_sec', 'x', 'y', 'endx', 'endy', 'pass_length', 'pass_subtype', 'pass_height', 'pass_cross', 'pass_body_part', 'pass_outcome', 'pass_recipient_id', 'pass_recipient_name', 'carry_length', 'shot_endx', 'shot_endy', 'shot_outcome', 'shot_xg', 'shot_body_part', 'shot_type', 'duel_type', 'duel_outcome', 'under_pressure', 'counterpress', 'outcome', 'success', 'league_season']\n",
      "   match_id  competition_id  season_id competition_name season_name  \\\n",
      "0   3754058               2         27   Premier League   2015/2016   \n",
      "1   3754058               2         27   Premier League   2015/2016   \n",
      "2   3754058               2         27   Premier League   2015/2016   \n",
      "3   3754058               2         27   Premier League   2015/2016   \n",
      "4   3754058               2         27   Premier League   2015/2016   \n",
      "\n",
      "                               event_id  event_index         type  \\\n",
      "0  9153e9f4-f69c-4e04-8f64-505592e212cd            1  Starting XI   \n",
      "1  3fbcf4e7-94d1-485a-be85-fd26a6af0318            2  Starting XI   \n",
      "2  06a9a4dc-d9c9-40f6-bd89-437ba7fe682d            3   Half Start   \n",
      "3  100362ee-9311-4187-bd8a-0201d9db2565            4   Half Start   \n",
      "4  2ca23eea-a984-47e4-8243-8f00880ad1c9            5         Pass   \n",
      "\n",
      "    play_pattern  player_id  ... shot_xg  shot_body_part shot_type  duel_type  \\\n",
      "0   Regular Play        NaN  ...     NaN            None      None       None   \n",
      "1   Regular Play        NaN  ...     NaN            None      None       None   \n",
      "2   Regular Play        NaN  ...     NaN            None      None       None   \n",
      "3   Regular Play        NaN  ...     NaN            None      None       None   \n",
      "4  From Kick Off     3343.0  ...     NaN            None      None       None   \n",
      "\n",
      "   duel_outcome under_pressure  counterpress   outcome success  \\\n",
      "0          None          False         False      None     NaN   \n",
      "1          None          False         False      None     NaN   \n",
      "2          None          False         False      None     NaN   \n",
      "3          None          False         False      None     NaN   \n",
      "4          None          False         False  Complete    True   \n",
      "\n",
      "                league_season  \n",
      "0  Premier League | 2015/2016  \n",
      "1  Premier League | 2015/2016  \n",
      "2  Premier League | 2015/2016  \n",
      "3  Premier League | 2015/2016  \n",
      "4  Premier League | 2015/2016  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "print(events_df.shape)\n",
    "print(events_df.columns.tolist())\n",
    "print(events_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f56851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shot_endy              0.992458\n",
      "shot_endx              0.992458\n",
      "shot_type              0.992458\n",
      "shot_body_part         0.992458\n",
      "shot_xg                0.992458\n",
      "shot_outcome           0.992458\n",
      "duel_outcome           0.988244\n",
      "duel_type              0.975422\n",
      "pass_subtype           0.937896\n",
      "pass_outcome           0.934358\n",
      "carry_length           0.789197\n",
      "pass_recipient_id      0.740958\n",
      "pass_recipient_name    0.740958\n",
      "pass_body_part         0.740791\n",
      "pass_height            0.719422\n",
      "pass_length            0.719422\n",
      "success                0.688529\n",
      "outcome                0.672208\n",
      "endx                   0.508619\n",
      "endy                   0.508619\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(events_df.isna().mean().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb39ccfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-monotonic within period: 0\n",
      "Non-monotonic absolute: 1\n"
     ]
    }
   ],
   "source": [
    "mid = events_df[\"match_id\"].sample(1).iloc[0]\n",
    "m = events_df[events_df.match_id == mid].copy()\n",
    "\n",
    "m = m.sort_values([\"period\",\"t_in_period_sec\",\"event_index\"])\n",
    "\n",
    "print(\"Non-monotonic within period:\",\n",
    "      (m.groupby(\"period\")[\"t_in_period_sec\"].diff().fillna(0) < 0).sum())\n",
    "\n",
    "print(\"Non-monotonic absolute:\",\n",
    "      (m[\"t_abs_sec\"].diff().fillna(0) < 0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0045c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique possessions in match: 216\n",
      "Max teams per possession: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique possessions in match:\", m[\"possession\"].nunique())\n",
    "\n",
    "# Check that possession doesn’t mix teams\n",
    "pos_team_check = (\n",
    "    m.groupby(\"possession\")[\"possession_team_id\"]\n",
    "     .nunique()\n",
    "     .max()\n",
    ")\n",
    "print(\"Max teams per possession:\", pos_team_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6fe626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "Pass              368619\n",
      "Ball Receipt*     340324\n",
      "Carry             276949\n",
      "Pressure          115402\n",
      "Ball Recovery      40943\n",
      "Duel               32290\n",
      "Clearance          21645\n",
      "Block              14839\n",
      "Dribble            13721\n",
      "Goal Keeper        11777\n",
      "Miscontrol         10786\n",
      "Dispossessed       10520\n",
      "Shot                9908\n",
      "Foul Committed      9512\n",
      "Foul Won            9112\n",
      "Name: count, dtype: int64\n",
      "Pass success rate: 0.7660457003030229\n",
      "Dribble success rate: 0.5866919320749217\n",
      "Shot outcomes:\n",
      "shot_outcome\n",
      "Off T               3197\n",
      "Blocked             2880\n",
      "Saved               2209\n",
      "Goal                 988\n",
      "Wayward              396\n",
      "Post                 170\n",
      "Saved Off Target      45\n",
      "Saved to Post         23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(events_df[\"type\"].value_counts().head(15))\n",
    "\n",
    "print(\"Pass success rate:\",\n",
    "      events_df[events_df.type==\"Pass\"][\"success\"].mean())\n",
    "\n",
    "print(\"Dribble success rate:\",\n",
    "      events_df[events_df.type==\"Dribble\"][\"success\"].mean())\n",
    "\n",
    "print(\"Shot outcomes:\")\n",
    "print(events_df[events_df.type==\"Shot\"][\"shot_outcome\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401224fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.313403e+06\n",
      "mean     1.638085e+00\n",
      "std      5.557648e+00\n",
      "min     -5.555650e+02\n",
      "25%      0.000000e+00\n",
      "50%      7.040000e-01\n",
      "75%      1.560000e+00\n",
      "max      4.143830e+02\n",
      "Name: dt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "events_df = events_df.sort_values([\"match_id\",\"period\",\"t_in_period_sec\",\"event_index\"])\n",
    "\n",
    "events_df[\"dt\"] = (\n",
    "    events_df.groupby(\"match_id\")[\"t_abs_sec\"]\n",
    "    .diff()\n",
    ")\n",
    "\n",
    "print(events_df[\"dt\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280deff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = events_df.sort_values([\"match_id\",\"minute\",\"second\",\"event_index\"]).copy()\n",
    "\n",
    "df[\"t_abs_fix\"] = 60*df[\"minute\"].fillna(0) + df[\"second\"].fillna(0)\n",
    "df[\"dt_fix\"] = df.groupby(\"match_id\")[\"t_abs_fix\"].diff()\n",
    "\n",
    "bad = df[df[\"dt_fix\"] < 0]\n",
    "print(\"Bad rows:\", len(bad))\n",
    "\n",
    "cols = [\"match_id\",\"event_index\",\"type\",\"period\",\"minute\",\"second\",\"timestamp\",\"t_abs_sec\",\"t_abs_fix\",\"dt_fix\"]\n",
    "print(bad[cols].head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
